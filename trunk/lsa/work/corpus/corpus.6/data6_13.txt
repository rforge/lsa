LSA ist ein Verfahren, das zur vollautomatischen Indizierung von Texten und zum Text-retrieval entwickelt worden. Um eine solche Indizierung durchzuführen müssen erstmals Dokumente und Worte als Vektoren dargestellt werden. Diese müssen sich allerdings in einem gleichen multidimensionalen Vektorraum befinden. Das Ziel liegt darin semantisch äquivalente, aber unterschiedlich geschriebene Wörter zu identifizieren. Kurz beschrieben kann dieses Verfahren in 3 Schritten durchgeführt werden. Der Zielsetzung, die Eingabe (Texte oder Textphrasen werden in einer einheitlichen Sprache eingegeben) und schlussendlich das Ergebnis: Eine Auflistung von Wörtern die zu einem Begriff semantisch äquivalent sein könnten. Genauer betrachtet werden die Daten, zur Datenmengenreduktion, in einem mathematischen  Verfahren bearbeitet. Dazu werden diese Daten in Form einer Matrix repräsentiert, und durch das System der Singular Value Decomposition (SVD) faktorisiert. Die zentrale Datenstruktur ist also die Matrix wobei Terme hierbei Worte sind, welche in mindestens zwei (bis ca. 1000-2000) Dokumenten vorkommen. Ein Element in dieser Matrix repräsentiert die Häufigkeit eines Terms innerhalb eines Dokuments. Anschließend wird die erstellte Matrix mittels SVD in drei weitere Matrizen mit linear unabhängigen Vektoren aufgespalten. 1) W0: Matrix der Eigenvektoren der quadratischen Matrix XXT. 2) D0:  Matrix der Eigenvektoren der quadratischen Matrix XTX. 3) S0:  Matrix der Eigenwerte der Eigenwert-Eigenvektor-Dekomposition. Die Zeilen und Spalten der Matrix S0 werden so vertauscht, dass die Werte der Größe nach geordnet auf der Mitteldiagonale liegen. Als letzter Schritt folgt die Reduzierung  der Dimensionalität der Matrix S0  auf S (gleichzeitige Reduzierung von Matrix W0 auf W und D0 auf D). Multipliziert man zu guter letzt die drei Matrizen S, W und D miteinander, kann man damit die im Text verborgenen semantischen Strukturen aufdecken. 
