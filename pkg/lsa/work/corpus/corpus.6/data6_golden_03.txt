Mit Hilfe der Latent Semantic Analysis wird versucht, semantisch äquivalente, aber unterschiedlich geschriebene Worte zu identifizieren, und zwar durch mathematische Methoden. Zuerst wird vom vorgegebenen Text eine Dokument/Wort Matrix erstellt, in die jedes einzelne Wort der Textpassage in Zusammenhang mit der Häufigkeit des Auftretens innerhalb des Textes/der Textstelle gebracht wird. Es wird weiters ein Wert errechnet, der sowohl nach der Relevanz des Wortes in dem untersuchten Abschnitt gewichtet ist, als auch nach dem Grad des Informationsgehaltes unabhängig von dem Text. Durch die folgende Singular Value Decomposition (SVD) wird eine Faktoranalyse durchgeführt und die Dokument/Wort Matrix in drei Matrizen auf gespalten, die erstens die originalen Zeileneinträge als Vektoren der orthogonalen Faktorwerte, zweitens die Spalteneinträge auf selbige Art und drittens (Diagonale) die singular values, die Skalenwerte enthalten, welche durch Multiplikation wieder die originären Matrixwerte ergeben. Nun werden die Werte neu sortiert und ausgerichtet, die Faktoren werden reduziert, sodass die Matrix in einem weniger dimensionalen Raum projezierbar ist. Nun können zwei Worte verglichen werden, indem die Entfernung der jeweiligen Wortvektoren innerhalb der reduzierten Matrix ermittelt wird und man kann auf diese Weise Rückschlüsse auf die semantische Bedeutung der Worte ziehen.
